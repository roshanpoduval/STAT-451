{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 (20 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 451: Machine Learning (Fall 2020)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "\n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat451-fs2020/\n",
    "\n",
    "---\n",
    "\n",
    "**Due**: Dec 04, (before 11:59 pm).\n",
    "\n",
    "**How to submit**\n",
    "\n",
    "As mentioned in the lecture, you need to send the `.ipynb` file with your answers plus an `.html` file, which will serve as a backup for us in case the `.ipynb` file cannot be opened on my or the TA's computer. In addition, you may also export the notebook as PDF and upload it as well.\n",
    "\n",
    "The homework solution should be uploaded on Canvas. You can submit it as often as you like before the deadline.\n",
    "\n",
    "\n",
    "**Important**\n",
    "\n",
    "- The cells that require your code answer are marked with `\"# YOUR CODE\"` comments.\n",
    "- Note that you may use 1 or more line of code for replacing each `\"# YOUR CODE\"` comment.\n",
    "\n",
    "For example, imagine there is a question asking you to implement a threshold function that should return 1 if the input `x` is greater than 0.5 and otherwise. This could appear as follows in the the exercise:\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    # YOUR CODE\n",
    "```\n",
    "\n",
    "A valid answer could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "```\n",
    "\n",
    "Another valid solution could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    return int(x > 0.5)\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roshan \n",
      "last updated: 2020-11-25 \n",
      "\n",
      "CPython 3.8.3\n",
      "IPython 7.16.1\n",
      "\n",
      "numpy 1.18.5\n",
      "scipy 1.5.0\n",
      "matplotlib 3.2.2\n",
      "sklearn 0.23.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Sebastian Raschka' -v -p numpy,scipy,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"paragraph\">\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "  <p><br></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Using Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be working with the *Pima Indians Diabetes Database* database by  [Vincent Sigillito](vgs@aplcen.apl.jhu.edu), which is available from the UCI database (https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) or OpenML (https://www.openml.org/d/37).\n",
    "\n",
    "\n",
    "The dataset contains information about 768 patients along with the Diabetes diagnosis. The Diabetes diagnosis is a binary label, where \"tested_positive\" means that a patient has diabetes and \"tested_negative\" means that a patient does not have diabetes.\n",
    "\n",
    "I additional to the class label, there are 8 numeric features in the dataset, which are listed below:\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1) Load the Dataset [2 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to load the dataset from the `dataset_37_diabetes.csv` CSV file located in the HW folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('dataset_37_diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2) Preprocess the class label [2 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the class label using pandas `apply` or `map` method. The mapping should be as follows:\n",
    "\n",
    "- `'tested_positive'` should be converted to `1`\n",
    "- `'tested_negative'` should be converted to `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "df['class'] = df['class'].map({'tested_positive': 1, 'tested_negative': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3) Split dataset into training and test sets [2 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset into 70% training and 30% test data\n",
    "- Perform a stratified split\n",
    "- use `0` as the random seed for shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = df['class'].values\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=.7, stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4) Gridsearch and model selection [4 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your task is to use `GridSearchCV` from scikit-learn to find the best parameters for `max_depth` and `criterion` for a decision tree. For max_depth, the values `[1, 2, 3, 4, 5, 10, 15, 20, None]` should be tried, and for criterion both Gini and Entropy should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 73.91%\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "param_grid = {'max_depth': [1, 2, 3, 4, 5, 10, 15, 20, None],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "gs = GridSearchCV(estimator=tree,\n",
    "                  param_grid=param_grid,\n",
    "                  n_jobs=-1,\n",
    "                  refit=True,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Accuracy: %.2f%%' % (gs.best_score_*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, print the best hyperparameters obtained from the `GridSearchCV` run. Also, compute the accuracy the model, which uses the best hyperparameter settings and was trained on the whole training set, on the test set (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'criterion': 'gini', 'max_depth': 2}\n",
      "Test Accuracy: 71.00%\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "\n",
    "print('Best Params: %s' % gs.best_params_)\n",
    "\n",
    "## model is already fit to the whole training set because  we used `refit=True` in GridSearchCV\n",
    "print('Test Accuracy: %.2f%%' % ((sum((gs.best_estimator_.predict(X_test) == y_test))/y_test.size)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Estimate the Generalization Performance using Bootstrap Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are asked to compute the accuracy of the model from the previous exercise (1.1), using the train set (`X_train`, `y_train`), via different bootstrap methods. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Compare the Out-of-Bag, .632, and .632+ bootstrap approaches [4 Pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computing the bootstrap estimates and confidence intervals, you are going to use the `bootstrap_point632_score` function implemented in MLxtend: \n",
    "http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\n",
    "\n",
    "The accruacy should be the mean accuracy over the 200 bootstrap values that the `bootstrap_point632_score` method returns.\n",
    "\n",
    "- For this, use the best model you obtained from the previous exercise 1.1.4)\n",
    "- use 200 bootstrap rounds\n",
    "- set the random seed to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.37%\n",
      "95% Confidence interval: [0.68, 0.80]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute Out-of-bag Bootstrap\n",
    "scores = bootstrap_point632_score(gs.best_estimator_, X_train, y_train, method='oob', n_splits=200, random_seed=1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.79%\n",
      "95% Confidence interval: [0.72, 0.79]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute .632 Bootstrap\n",
    "scores = bootstrap_point632_score(gs.best_estimator_, X_train, y_train, n_splits=200, random_seed=1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.38%\n",
      "95% Confidence interval: [0.71, 0.79]\n"
     ]
    }
   ],
   "source": [
    "#------------------#\n",
    "##### STUDENTS #####\n",
    "#------------------#\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute .632+ Bootstrap\n",
    "scores = bootstrap_point632_score(gs.best_estimator_, X_train, y_train, method='.632+', n_splits=200, random_seed=1)\n",
    "\n",
    "\n",
    "# Compute accuracy (average over the bootstrap rounds)\n",
    "acc = np.mean(scores)\n",
    "print('Accuracy: %.2f%%' % (100*acc))\n",
    "\n",
    "# Compute the 95% confidence interval around the accuracy estimate\n",
    "lower = np.percentile(scores, 2.5)\n",
    "upper = np.percentile(scores, 97.5)\n",
    "print('95%% Confidence interval: [%.2f, %.2f]' % (lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Analyzing the different bootstrap results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) [2 Pts] Based on what you have learned it class, which of the three bootstrap methods (out-of-bag, 0.632, or 0.632+) do you expect to yield a generalization accuracy estimate from the training set that is closest to the true generalization performance of the model? Explain your reasoning in 1-3 sentences. (Tip: Think about optimistic and pessimistic bias).\n",
    "\n",
    "\n",
    "According to the lecture that showed 95% confidence intervals for bootstrapping methods, the OOB is pessimistically biased.\n",
    "Similarly, we can see that the .632 bootstrap is overly optimistic. The .632+ bootstrap was designed to not suffer from the same optimistic bias that .632 suffers from, so I expect .632+ bootstrap to have the least bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2) [2 Pts] Based on your observations from the experiment in 1.2.1), which bootstrap approach (out-of-bag, 0.632, or 0.632+) yields an accuracy estimate from the training dataset that is closest to the test set accuracy from exercise 1.1.4? Is this reasonable? Explain your answer in 1-3 sentences. Also, to answer this question, assume that the test set accuracy from 1.1.4) is a perfect estimate of the true generalization accuracy of the model. \n",
    "\n",
    "The oob on the training set was closest to the test set accuracy, although all bootstrapping methods in my case were overly optimistic. This is reasonabe because there are only ~800 records in our full dataset and we are using a high number of splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3) [2 Pts] Based on your observations from the experiment in 1.2.1), are the overall results consistent with what you expected in your answer above (question 1))? Explain your reasoning in 3-5 sentences. Also, to answer this question, assume that the test set accuracy from 1.1.4) is a perfect estimate of the true generalization accuracy of the model. \n",
    "\n",
    "Tip: Discuss which methods are optimistically and pessimistically biased and whether this was expected.\n",
    "\n",
    "The results I found were surprising. I expected the oob to be pessimistic. It turned out to just be the least optimistically biased. Perhaps if we used a different number of splits, or a larger dataset, we would be able to see more significant results. Overall, even though all the bootstrap methods seemed optimistically biased, the ordering of the scores they produced was expected (oob < .632+ < .632)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
